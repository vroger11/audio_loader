{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "from audio_loader.features.raw_audio import WindowedAudio\n",
    "from audio_loader.features.log_mel import WindowedLogMel\n",
    "from audio_loader.ground_truth.timit import TimitGroundTruth\n",
    "from audio_loader.samplers.dynamic_sampler import DynamicSampler\n",
    "from audio_loader.dl_frontends.pytorch.fill_ram import get_dataset_dynamic_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimitMELDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, data_dir, batch_size):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.timit_gt = TimitGroundTruth(self.data_dir, with_silences=False)\n",
    "        self.mel_feature_processor = WindowedLogMel(400, 160, 16000, 40, normalize=False)#, delta_orders=[2])\n",
    "        self.mel_sampler = DynamicSampler([self.mel_feature_processor], self.timit_gt)\n",
    "        self.original_train_dataset, self.collate_func = get_dataset_dynamic_size(self.mel_sampler, \"train\")\n",
    "        self.test_dataset, self.collate_func = get_dataset_dynamic_size(self.mel_sampler, \"test\")\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.val_nb_samples = round(len(self.original_train_dataset)/100)\n",
    "            self.train_nb_samples = len(self.original_train_dataset) - self.val_nb_samples\n",
    "            self.train_dataset, self.val_dataset = random_split(\n",
    "                self.original_train_dataset,\n",
    "                [self.train_nb_samples, self.val_nb_samples]\n",
    "            )\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            return\n",
    "            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True,\n",
    "                          collate_fn=self.collate_func,\n",
    "                          drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        #return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "        #                  collate_fn=self.collate_func,\n",
    "        #                  drop_last=False)\n",
    "        return DataLoader(self.test_dataset, self.batch_size , shuffle=False,\n",
    "                          collate_fn=self.collate_func,\n",
    "                          drop_last=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, self.batch_size , shuffle=False,\n",
    "                          collate_fn=self.collate_func,\n",
    "                          drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data\n",
    "mel_timit = TimitMELDataModule(join(Path.home(), \"data/kaggle_TIMIT\"), 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lit_mel_model(pl.LightningModule):\n",
    "    def __init__(self, feature_size):\n",
    "        \"\"\"Init all parameters.\n",
    "        \n",
    "        feature_size: int\n",
    "            size of the expected features for the forward step\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.feature_size = feature_size\n",
    "        \n",
    "        self.layer_1_grus = nn.GRU(\n",
    "            feature_size, 550, 5,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "        self.bn_fwd = nn.BatchNorm1d(550)\n",
    "        self.bn_bwd = nn.BatchNorm1d(550)\n",
    "        self.layer_2_dense = torch.nn.Linear(1100, 128)\n",
    "        self.bn_layer_2 = nn.BatchNorm1d(128)\n",
    "        self.act_layer_2 = nn.LeakyReLU(0.1) # in pytorch kaldi it is softmax\n",
    "        \n",
    "        self.layer_3_dense = torch.nn.Linear(128, 58)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward of the model over the data.\"\"\"\n",
    "        batch_size = x.batch_sizes[0]\n",
    "        # shape: (num_layers*directions, batch_size, hidden_size?)\n",
    "        h_0 = torch.zeros(5*2, batch_size, 550, device=\"cuda\")\n",
    "        output, h_n = self.layer_1_grus(x, h_0)\n",
    "\n",
    "        fwd_h = h_n.view(5, 2, batch_size, 550)[-1, 0]\n",
    "        bwd_h = h_n.view(5, 2, batch_size, 550)[-1, 1]\n",
    "    \n",
    "        fwd_h = self.bn_fwd(fwd_h.view(batch_size, 550))\n",
    "        bwd_h = self.bn_bwd(bwd_h.view(batch_size, 550))\n",
    "\n",
    "        h = torch.cat((fwd_h, bwd_h), 1)\n",
    "        dense1 = self.bn_layer_2(self.act_layer_2(self.layer_2_dense(h)))\n",
    "        return self.layer_3_dense(dense1)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.0004)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x.to('cuda'))\n",
    "        _, y = torch.stack(y).max(dim=1)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x.to('cuda'))\n",
    "        _, target = torch.stack(y).max(dim=1)\n",
    "        _, pred = y_hat.max(dim=1)\n",
    "\n",
    "        loss = F.cross_entropy(y_hat, target)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_accuracy', accuracy(pred+1, target+1))\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x.to('cuda'))\n",
    "        _, target = torch.stack(y).max(dim=1)\n",
    "        _, pred = y_hat.max(dim=1)\n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, target)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_accuracy', accuracy(pred+1, target+1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lit_mel_model(\n",
       "  (layer_1_grus): GRU(40, 550, num_layers=5, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (bn_fwd): BatchNorm1d(550, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn_bwd): BatchNorm1d(550, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer_2_dense): Linear(in_features=1100, out_features=128, bias=True)\n",
       "  (bn_layer_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act_layer_2): LeakyReLU(negative_slope=0.1)\n",
       "  (layer_3_dense): Linear(in_features=128, out_features=58, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init model\n",
    "model = lit_mel_model(40*1) # log MEl band\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "# trainer definition\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=10, mode=\"min\")\n",
    "    ],\n",
    "    checkpoint_callback=ModelCheckpoint(save_top_k=5, monitor=\"val_loss\", mode=\"min\"),\n",
    "    progress_bar_refresh_rate=1000,\n",
    "    gpus=1, auto_select_gpus=True,\n",
    "    precision=16,\n",
    "    max_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type        | Params\n",
      "----------------------------------------------\n",
      "0 | layer_1_grus  | GRU         | 23 M  \n",
      "1 | bn_fwd        | BatchNorm1d | 1 K   \n",
      "2 | bn_bwd        | BatchNorm1d | 1 K   \n",
      "3 | layer_2_dense | Linear      | 140 K \n",
      "4 | bn_layer_2    | BatchNorm1d | 256   \n",
      "5 | act_layer_2   | LeakyReLU   | 0     \n",
      "6 | layer_3_dense | Linear      | 7 K   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/13977 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vroger/.miniconda3/envs/audio_loader/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/vroger/.miniconda3/envs/audio_loader/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  72%|███████▏  | 10000/13977 [07:50<03:06, 21.27it/s, loss=1.300, v_num=105]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▊  | 11000/13977 [08:09<02:12, 22.46it/s, loss=1.300, v_num=105]\n",
      "Epoch 0:  86%|████████▌ | 12000/13977 [08:18<01:22, 24.09it/s, loss=1.300, v_num=105]\n",
      "Epoch 0:  93%|█████████▎| 13000/13977 [08:33<00:38, 25.31it/s, loss=1.271, v_num=105]\n",
      "Epoch 1:  72%|███████▏  | 10000/13977 [07:56<03:09, 20.99it/s, loss=1.230, v_num=105]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 11000/13977 [08:13<02:13, 22.27it/s, loss=1.230, v_num=105]\n",
      "Epoch 1:  86%|████████▌ | 12000/13977 [08:20<01:22, 23.95it/s, loss=1.230, v_num=105]\n",
      "Epoch 1:  93%|█████████▎| 13000/13977 [08:34<00:38, 25.28it/s, loss=1.266, v_num=105]\n",
      "Epoch 2:  72%|███████▏  | 10000/13977 [07:12<02:52, 23.12it/s, loss=1.079, v_num=105]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 11000/13977 [07:30<02:01, 24.44it/s, loss=1.079, v_num=105]\n",
      "Epoch 2:  86%|████████▌ | 12000/13977 [07:37<01:15, 26.25it/s, loss=1.079, v_num=105]\n",
      "Epoch 2:  93%|█████████▎| 13000/13977 [07:50<00:35, 27.63it/s, loss=1.016, v_num=105]\n",
      "Epoch 3:  72%|███████▏  | 10000/13977 [07:11<02:51, 23.15it/s, loss=1.008, v_num=105]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 11000/13977 [07:29<02:01, 24.49it/s, loss=1.008, v_num=105]\n",
      "Epoch 3:  86%|████████▌ | 12000/13977 [07:36<01:15, 26.30it/s, loss=1.008, v_num=105]\n",
      "Epoch 3:  93%|█████████▎| 13000/13977 [07:50<00:35, 27.65it/s, loss=0.949, v_num=105]\n",
      "Epoch 4:   7%|▋         | 1000/13977 [01:01<13:20, 16.21it/s, loss=0.872, v_num=105] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vroger/.miniconda3/envs/audio_loader/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:   7%|▋         | 1000/13977 [01:08<14:52, 14.55it/s, loss=0.872, v_num=105]\n",
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vroger/.miniconda3/envs/audio_loader/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:  80%|████████  | 3000/3742 [00:21<00:05, 136.36it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': tensor(0.6699, device='cuda:0'),\n",
      " 'test_loss': tensor(1.0169, device='cuda:0'),\n",
      " 'train_loss': tensor(0.5585, device='cuda:0'),\n",
      " 'val_accuracy': tensor(0.6622, device='cuda:0'),\n",
      " 'val_loss': tensor(1.0352, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing:  80%|████████  | 3000/3742 [00:27<00:06, 109.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'train_loss': 0.5585184097290039,\n",
       "  'val_loss': 1.035223126411438,\n",
       "  'val_accuracy': 0.6622452735900879,\n",
       "  'test_loss': 1.016899824142456,\n",
       "  'test_accuracy': 0.6698864102363586}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, mel_timit)\n",
    "\n",
    "mel_timit.setup(\"test\")\n",
    "trainer.test(model, mel_timit.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
